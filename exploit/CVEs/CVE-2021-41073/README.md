<!--toc:start-->
- [io_provide_buffers](#ioprovidebuffers)
- [io_rw](#iorw)
- [漏洞点](#漏洞点)
- [漏洞利用](#漏洞利用)
- [Ftrace 使用](#ftrace-使用)
- [引用](#引用)
<!--toc:end-->

# io_provide_buffers
这个标识位被用来指定传入的SQE的操作类型,具体可以查看man手册,在`io_uring_enter`系统调用中被使用
```c
/*
 * IO submission data structure (Submission Queue Entry)
 */
struct io_uring_sqe {
	__u8	opcode;		/* type of operation for this sqe */
	__u8	flags;		/* IOSQE_ flags */
	__u16	ioprio;		/* ioprio for the request */
	__s32	fd;		/* file descriptor to do IO on */
    .......
}
```
这个命令用来在在用户层注册一个缓冲区组用来读取/接受数据,使用该操作可以用来消除poll+read的割裂感

这里的poll系统调用是一种IO多路复用机制,是被用来告知内核来监控文件的变化然后通知用户进行处理,而不是用户IO后发现文件暂时不可操作而进行阻塞,这样极大提升了工作效率

让我们再说回`IORING_OP_PROVIDE_BUFFEERS`,这个io_uring_sqe所代表的操作将允许用户能够拥有内核中已经就绪的缓存池,当文件或者套接字准备好被读取/被接受数据,一个缓冲区将被选中来做该项操作

这些被创造的缓冲区通过group ID来管理,当提交一个请求,用户通过设置`IOSQE_BUFFER_SELECT`指定一个提供的缓冲区并且指定groupID
当操作完成,groupID的缓冲区将被作为CQE来返回给用户

而要搞清楚这个操作符干了什么,最好的办法也就是自己看一遍源码
这里我们可以从`io_uring_enter()`看起,直到函数`io_issue_sqe()`

```c
    ...
	case IORING_OP_PROVIDE_BUFFERS:
		ret = io_provide_buffers(req, issue_flags);
		break;
    ...

```
该函数通过`struct io_uring_sqe`结构体当中的opcode来判断操作,最终调用`io_provide_buffers()`函数

```c

static int io_provide_buffers(struct io_kiocb *req, unsigned int issue_flags)
{
    ...

	ret = io_add_buffers(p, &head);
    ...

	return 0;
}


static int io_add_buffers(struct io_provide_buf *pbuf, struct io_buffer **head)
{
	struct io_buffer *buf;
	u64 addr = pbuf->addr;
	int i, bid = pbuf->bid;

	for (i = 0; i < pbuf->nbufs; i++) {
		buf = kmalloc(sizeof(*buf), GFP_KERNEL_ACCOUNT);
		if (!buf)
			break;

		buf->addr = addr;
		buf->len = min_t(__u32, pbuf->len, MAX_RW_COUNT);
		buf->bid = bid;
		addr += pbuf->len;
		bid++;
		if (!*head) {
			INIT_LIST_HEAD(&buf->list);
			*head = buf;
		} else {
			list_add_tail(&buf->list, &(*head)->list);
		}
		cond_resched();
	}

	return i ? i : -ENOMEM;
}

```
可以看到当我们使用该操作类型来发起`io_uring_enter`系统调用提交sqe的时候,内核会调用`io_provide_buffers()`每个buffer分配`struct io_buffer`,他们之间通过`struct list_head`进行连接

```c
struct io_buffer {
	struct list_head list;
	__u64 addr;
	__u32 len;
	__u16 bid;
};
```

# io_rw
当我们提交的SQE中opcode为`IO_OP_READ|IO_OP_READV|IO_OP_READ_FIXED|IO_OP_WRITE|IO_OP_WRITEV|IO_OP_WRITE_FIXED`时,就会调用io_rw类似函数,例如`io_read/write`

如果我们发起的请求当中包含IOSQE_BUFFER_SELECT的时候,在内核源码中该标识符被设置于`struct io_uring_sqe(__u32 opcode)`当中

当该标识符设置时,内核在真正执行io_*函数来处理IO操作时,会查看是否为rw操作,
若是则再检查提交是否含有`IOSQE_BUFFER_SELECT`标识位(或是`REQ_F_BUFFER_SELECT`,这里两者在io_uring.c中的一个枚举类型中划了等号)则会首先调用`io_rw_buffer_select()`

```c
static void __user *io_rw_buffer_select(struct io_kiocb *req, size_t *len,
					bool needs_lock)
{
	struct io_buffer *kbuf;
	u16 bgid;

	kbuf = (struct io_buffer *) (unsigned long) req->rw.addr;
	bgid = req->buf_index;
	kbuf = io_buffer_select(req, len, bgid, kbuf, needs_lock);
	if (IS_ERR(kbuf))
		return kbuf;
	req->rw.addr = (u64) (unsigned long) kbuf;
	req->flags |= REQ_F_BUFFER_SELECTED;
	return u64_to_user_ptr(kbuf->addr);
}
```

这里发现存在些许的问题,因为我们`req->rw.addr = (u64)(unsigned long)kbuf` 
这里我们本该存储用户区域读写地址的字段给赋值为内核区域io_buffer的地址,
一般同一个字段在不同时间段存在内核或用户地址总是会出现混淆的问题,这也引出了一个漏洞点

# 漏洞点
这里介绍一个内核函数`loop_rw_iter()`
```c
/*
 * For files that don't have ->read_iter() and ->write_iter(), handle them
 * by looping over ->read() or ->write() manually.
 */
static ssize_t loop_rw_iter(int rw, struct io_kiocb *req, struct iov_iter *iter)
{
	struct kiocb *kiocb = &req->rw.kiocb;
	struct file *file = req->file;
	ssize_t ret = 0;

	/*
	 * Don't support polled IO through this interface, and we can't
	 * support non-blocking either. For the latter, this just causes
	 * the kiocb to be handled from an async context.
	 */
	if (kiocb->ki_flags & IOCB_HIPRI)
		return -EOPNOTSUPP;
	if (kiocb->ki_flags & IOCB_NOWAIT)
		return -EAGAIN;

	while (iov_iter_count(iter)) {
		struct iovec iovec;
		ssize_t nr;

		if (!iov_iter_is_bvec(iter)) {
			iovec = iov_iter_iovec(iter);
		} else {
			iovec.iov_base = u64_to_user_ptr(req->rw.addr);
			iovec.iov_len = req->rw.len;
		}

		if (rw == READ) {
			nr = file->f_op->read(file, iovec.iov_base,
					      iovec.iov_len, io_kiocb_ppos(kiocb));
		} else {
			nr = file->f_op->write(file, iovec.iov_base,
					       iovec.iov_len, io_kiocb_ppos(kiocb));
		}

		if (nr < 0) {
			if (!ret)
				ret = nr;
			break;
		}
		ret += nr;
		if (nr != iovec.iov_len)
			break;
		req->rw.len -= nr;
		req->rw.addr += nr;
		iov_iter_advance(iter, nr);
	}

	return ret;
}
```
正如其注释所说,当一个file文件没有实现`read_iter()`和`write_iter`时将会调用它,但是我们注意到最后几行
也就是`req->rw.addr += nr;`,可以看到对于我们上面提到的值加上了nr

然后我们这里为了举例因此查看`io_read()`函数,这个函数在我们提交SQE中的opcode为`IO_OP_READ|IO_OP_READV|IO_OP_WRITE_FIXED`时会进行调用,调用链条如下:

```
io_read()
    io_import_iovec()
        io_iov_buffer_select()
            __io_iov_buffer_select()
                io_rw_buffer_select()       #如果有REQ_F_BUFFER_SELECT,则req->rw.addr被设置为一个内核buffer的地址
        kiocb_done()
            io_put_rw_kbuf()
                io_put_kbuf()               #kfree
```

给出`io_put_kbuf()`函数
```c
static unsigned int io_put_kbuf(struct io_kiocb *req, struct io_buffer *kbuf)
{
	unsigned int cflags;

	cflags = kbuf->bid << IORING_CQE_BUFFER_SHIFT;
	cflags |= IORING_CQE_F_BUFFER;
	req->flags &= ~REQ_F_BUFFER_SELECTED;
	kfree(kbuf);
	return cflags;
}


static inline unsigned int io_put_rw_kbuf(struct io_kiocb *req)
{
	struct io_buffer *kbuf;

	kbuf = (struct io_buffer *) (unsigned long) req->rw.addr;
	return io_put_kbuf(req, kbuf);
}

```
我们可以看到在`io_put_rw_kbuf()`函数赋值`kbuf = req->rw.addr`
而这里注意一点如果我们的SQE中的flags字段带有`IOSQE_BUFFER_SELECT`,那么此时的`req->rw.addr`字段就是一个内核地址
所以此时`io_put_kbuf()`函数中`kfree(kbuf)`就等同于`kfree(req->rw.addr)`
因此如果我们在io_read()函数中调用的是`loop_rw_iter()`,那么就可以修改这个req->rw.addr的值,而且这还可以是一个内核地址,然后最后io_read退出时调用到的`io_put_kbuf`就可以实现任意地址释放的功能
`kfree(req->rw.addr + user_controlled_value);`

# 漏洞利用
这里梳理一下整个漏洞的攻击链条
1. 首先由于整个exploit需要使用多线程来达到,因此我们需要将每个线程绑定在同一个CPU里面
    ```c
    /* 为本进程的后续内存分配都集中在CPU1上 */
    /* 初始化CPU集合cpuset */
    CPU_ZERO(&cpuset);
    /* 将指定的CPU添加到CPU集合 */
    CPU_SET(1, &cpuset);
    /* 设置本进程对于cpuset里面标记的亲和性 */
    sched_setaffinity(0, sizeof(cpu_set_t), &cpuset);
    ```
2. 然后我们这里需要预创建两个io线程(io1, io2)和3个setxattr(sa1, sa2, sa3)线程,这些线程也都需要绑定相同的CPU,这里我们会使用多个互斥锁来保证程序的同步,从这里开始这些新建的线程应该都处于阻塞状态,所有的锁都被主线程掌控
3. 这里还需要利用一个io_uring相关的数据结构体
    ```c
struct io_tctx_node {
	struct list_head	ctx_node;
	struct task_struct	*task;
	struct io_ring_ctx	*ctx;
};
    ```
该结构体的创建时机是在某个线程在第一次使用io_uring相关系统调用时创建,用来保存该线程所使用io_uring的一些上下文信息,大小也为0x20,这里会存放task_struct的信息,而分配`io_tctx_node`也是需要使用同一个CPU分配,因此这里可以利用io_uring的一个设置
    ```c
if (0 != io_uring_register_iowq_aff(&ring, sizeof(cpu_set_t), &cpuset))    // io_uring_register_iowq_aff() —— set affinity of iou_wrk
{
    fprintf(stderr, "++ register failed: %m\n");
    exit(1);
}
    ```
这里是将io_wq线程创建`struct io_tctx_node`将选择cpuset集合里面的CPU进行创建
3. 主线程开始发力,需要堆喷大量的io_buffer,这个io_buffer大小为0x20,因此从kmalloc-32公用池当中分配,这样就会导致我们下次分配的kmalloc-32中的chunk前全是`struct io_buffer`,而我们分配这样一个io_buffer只需要调用`io_uring`中的某个具体操作`IORING_OP_PROVIDE_BUFFERS`,这里我们可以方便的使用liburing来进行操作
4. 然后主线程释放lock1,此时io1获取到了lock1继续运行,且此时主线程立刻调用setxattr+fuse将自己阻塞3s,这里会创建一个临时的0x20的chunk,恰好位于1000个io_buffer后面
5. io1在尝试获取锁之前会自行分配两个io_buffer来取消`io_tctx_node`的影响,在获取锁后io1正常运行,然后进行漏洞的利用,也就是`io_read + selected_buffer`,我们读0x20字节会导致最后分配的io_buffer脱链条(LIFO),然后释放掉(freed_io_buffer+0x20)地址位置的0x20堆块,也就是我们刚刚分配给setxattr的临时buffer,然后我们释放掉lock1,现在会导致io2获取到了lock1,然后使用io_uring来分配2个io_buffer,但在分配前会首先分配一个`io_tctx_node`,而分配给这个结构体的0x20大小的chunk则是我们刚刚释放掉的selected_buffer,然后io2接下来再次自行阻塞,尝试获取lock4
6. 当过了3秒之后,主线程恢复运行,但我们要知道此时设置setxattr的chunk里面存放的是`struct io_tctx_node`结构体的内容,而这里面的内容包含`task_struct`的地址,因此我们就能很简单的通过getxattr来获取该地址
7. 之后我们可以利用相同的方法来获取kaslr的值,我们只需要将`io_tctx_node`的创建转换为`seq_operations`结构体的创建即可泄漏内核函数地址,从而导致获取kaslr值
8. 然后我们重新堆喷,这样给之后的多个线程分别运行来进行布局,首先主线程释放lock3,然后三个线程`sa1, sa2, sa3`顺序获取锁,然后运行,这三个线程将分别首先使用setxattr来构造伪造的`struct bpf_prog`,主要伪造的部分是`insns[], *bpf_func`,后面的那个部分是bpf程序运行时需要调用的函数
    ```c
    struct bpf_prog {
        u16			pages;		/* Number of allocated pages */
        u16			jited:1,	/* Is our filter JIT'ed? */
                    jit_requested:1,/* archs need to JIT the prog */
                    gpl_compatible:1, /* Is filter GPL compatible? */
                    cb_access:1,	/* Is control block accessed? */
                    dst_needed:1,	/* Do we need dst entry? */
                    blinded:1,	/* Was blinded */
                    is_func:1,	/* program is a bpf function */
                    kprobe_override:1, /* Do we override a kprobe? */
                    has_callchain_buf:1, /* callchain buffer allocated? */
                    enforce_expected_attach_type:1, /* Enforce expected_attach_type checking at attach time */
                    call_get_stack:1; /* Do we call bpf_get_stack() or bpf_get_stackid() */
        enum bpf_prog_type	type;		/* Type of BPF program */
        enum bpf_attach_type	expected_attach_type; /* For some prog types */
        u32			len;		/* Number of filter blocks */
        u32			jited_len;	/* Size of jited insns in bytes */
        u8			tag[BPF_TAG_SIZE];
        struct bpf_prog_stats __percpu *stats;
        int __percpu		*active;
        unsigned int		(*bpf_func)(const void *ctx,
                            const struct bpf_insn *insn);
        struct bpf_prog_aux	*aux;		/* Auxiliary fields */
        struct sock_fprog_kern	*orig_prog;	/* Original BPF program */
        /* Instructions for interpreter */
        struct sock_filter	insns[0];
        struct bpf_insn		insnsi[];
    };
    ```
9. 然后主线程此时首先调用真正的ebpf系统调用,然后借此分配0x20大小的`sk_filter`对象,然后再次利用漏洞将该`sk_filter`释放,然后此时使用setxattr来重新分配到该`sk_filter`,此时就可以对其进行修改,修改其中的`prog`指针指向我们刚刚所伪造的bpf_prog,然后当下次我们使用该过滤器的时候将会导致任意代码执行,有效的提权方式就是修改`task_struct->cred`中的uid为0
    ```c
    struct sk_filter {
        refcount_t	refcnt;
        struct rcu_head	rcu;
        struct bpf_prog	*prog;
    };
    ```








# Ftrace 使用
我们需要在内核中自行挂载该临时文件系统,挂载方式如下:
```
mount -t tracefs nodev /sys/kernel/tracing  //挂载tracefs
mount -t debugfs debugfs /sys/kernel/debug  //挂载debugfs
```
在我看来似乎两者差距不大,但是gpt给出的回答是tracefs更加适合性能调优,debugfs的使用场景则是深入了解操作系统内部状态

在挂载成功后我们可以来使用其提供的文件接口
这个文件用来查看当前的追踪者类型
```
/ # cat /sys/kernel/debug/tracing/current_tracer 
nop
```
其中类型我们可以通过`available_tracers`文件来查看
```
/sys/kernel/debug/tracing # cat available_tracers 
blk function_graph function nop
```
我们也可以查看trace是否开启
```
/sys/kernel/debug/tracing # cat tracing_on
1
```
下面正式使用ftrace


1. 设置tracer类型,这里设置为function
```
echo function > current_tracer
```
2. 设置过滤函数(tracer类型为function的情况下,这里的可选函数也可通过`available_filter_functions`)
```
echo dev_attr_show > set_ftrace_filter
```
除了追踪某些特定函数,也可以输出事件,我们可以通过命令`ls events`来查看

而chompie师傅是采用了trace event来进行追踪
我们可以方便的在内核启动参数添加trace_event=kmem:kmalloc,kmem:kfree来进行查看,此外我们也可以添加`no_hash_pointers`内核参数来删除虚拟内存地址的打印

3. 查看追踪信息,这里我们的trace记录要清空也很简单,`echo 0 > trace`
```
cat trace
```


# 引用
[chompie复现](https://chomp.ie/Blog+Posts/Put+an+io_uring+on+it+-+Exploiting+the+Linux+Kernel)

[bsauce复现](https://bsauce.github.io/2022/07/11/CVE-2021-41073/#3-1-%E5%8E%9F%E8%AF%AD%E8%BD%AC%E5%8C%96%E4%BB%8E%E7%B1%BB%E5%9E%8B%E6%B7%B7%E6%B7%86%E5%88%B0uaf)
[Ftrace的使用](https://blog.csdn.net/u012489236/article/details/119519361)
